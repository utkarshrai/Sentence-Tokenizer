{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer\n",
    "A tokenizer is an algorithm that takes a string of text, and returns a list of sentences, where each sentence is a string in which words and punctuation marks are separated by spaces.\n",
    "\n",
    "The challenge was try and come up with the most effective tokenizer within 25 lines of python code. No libraries were used. ( We used the time module to time how fast the code was, I guess that is allowed.)\n",
    "\n",
    "If we remove the function definitions and return statements, the initial code was roughly 25 lines but to fix the spaces and lower case sentence breaks I had to add a fix function which was 6 more lines of code.\n",
    "I still tried my best and this works on all the test cases given in the doc perfectly.\n",
    "https://docs.google.com/document/d/1-XesZPeOSeOdAzLAPQNjSUP58gHwTuKo6bkHuNDrSi0/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sentence_Tokenizer(text):\n",
    "   end = True\n",
    "   sentences = []\n",
    "   while end > -1:\n",
    "       end = the_ends(text)\n",
    "       if end > -1:\n",
    "           sentences.append(text[end:].strip())\n",
    "           text = text[:end]\n",
    "   sentences.append(text)\n",
    "   sentences.reverse()\n",
    "   return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How effective is this?\n",
    "I was more concerned about the given test cases and there may be several issues I may have skipped. I additionally added abbreviations, it's a list we could keep adding however many we want. Any suggestions are heartily welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abb = {'dr.': 'doctor', 'mr.': 'mister', 'mrs.': 'mistress', 'ms.': 'miss','i.e.': 'that is', 'e.g.': 'for example'}\n",
    "terminators = ['.', '!', '?']\n",
    "wrappers = ['\"', \"'\", ')', ']', '}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def the_ends(text):\n",
    "    [end_now, special] = [[], []]\n",
    "    contractions = abb.keys()\n",
    "    sentence_terminators = terminators + [terminator + wrapper for wrapper in wrappers for terminator in terminators]\n",
    "    for sentence_terminator in sentence_terminators:\n",
    "        t_indices = list(find_all(text, sentence_terminator))\n",
    "        end_now.extend(([] if not len(t_indices) else [[i, len(sentence_terminator)] for i in t_indices]))\n",
    "    for contraction in contractions:\n",
    "        c_indices = list(find_all(text, contraction))\n",
    "        special.extend(([] if not len(c_indices) else [i + len(contraction) for i in c_indices]))\n",
    "    end_now = [pe for pe in end_now if pe[0] + pe[1] not in special]\n",
    "    if len(text) in [pe[0] + pe[1] for pe in end_now]:\n",
    "        max_end_start = max([pe[0] for pe in end_now])\n",
    "        end_now = [pe for pe in end_now if pe[0] != max_end_start]\n",
    "    end_now = [pe[0] + pe[1] for pe in end_now if sum(pe) > len(text) or (sum(pe) < len(text) and text[sum(pe)] == ' ')]\n",
    "    end = (-1 if not len(end_now) else max(end_now))\n",
    "    return end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we used\n",
    "Essentially I looked at this task as simple string manipulation, we shielded our wrappers and abbreviations, searched for our termintors and sliced the paragraph into sentences. Please leave a comment on any part of code you wish to know about.\n",
    "\n",
    "Some lines were 100 characters long which violates the \"Pandaorable\" clause of 80! But it's still close to the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1:\n",
    "            return\n",
    "        yield start\n",
    "        start += len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What went wrong and why Fix_1, additional code?\n",
    "In order to shorten the code it got pretty messed up and while it was tokenizing correctly, it was simply breaking sentences as soona s it saw a . or an ! even if the text had ... or !!! followed by lower case letters, so that was fixed and used up additional 6 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Fix_1(text):\n",
    "    sentences=Sentence_Tokenizer(text)\n",
    "    for i in range(len(sentences)):\n",
    "     sentences[i]=(((sentences[i].replace(\"!\",\" !\")).replace(\".\",\" .\")).replace(\". . .\",\"...\")).replace(\"?\",\" ?\")\n",
    "     if ((sentences[i])[0].isupper())!=True:\n",
    "        sentences[i-1]+=\" \"+(sentences[i])\n",
    "        del sentences[i]\n",
    "    return sentences    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Fix_1,\n",
    "The test cases run fine as can be seen below.\n",
    "\n",
    "I'm still working on shortening the code further to within 25 lines and will upload  a .py file soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ! !']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fix_1(\"Hello!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ! ! :-)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fix_1(\"Hello!! :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ... and goodbye']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fix_1(\"Hello... and goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ...', 'Goodbye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fix_1(\"Hello... Goodbye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How fast is this? Over 3500 texts/second!\n",
    "The required was 1000, maybe a block of code extra but the speed compensates.\n",
    "\n",
    "Machine on which run: i3 with 4GB ram, Kali linux\n",
    "\n",
    "Could have been faster if there was less stuff loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0002853870391845703 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "Fix_1(\"Hello... and goodbye\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
